{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZReapPi_xl1"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.layers.embeddings import Embedding\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-ld4whG_01-",
    "outputId": "e5dc195c-dc94-49cf-dd77-38afec4e0f6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Data used here is present in \"train.europarl\"\n",
    "file = open(\"train.europarl\", mode='rt', encoding='utf-8')\n",
    "trainlines = file.readlines()\n",
    "len(trainlines) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uy184FvoADQ9",
    "outputId": "ae6bf53e-3c25-42d9-a335-bbe39bfdd5c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Data used here is present in \"test.europarl\"\n",
    "file = open(\"test.europarl\", mode='rt', encoding='utf-8')\n",
    "testlines = file.readlines()\n",
    "len(testlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YH0qal1Crdb"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter()\n",
    "traindata = [] \n",
    "for line in trainlines:\n",
    "    linesplit = re.sub(\"\\W\",\" \",line.lower())\n",
    "    linesplit = linesplit.split()\n",
    "    for word in linesplit:\n",
    "        counts[word] += 1\n",
    "    traindata.append(linesplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-QMO1kGINdGw"
   },
   "outputs": [],
   "source": [
    "newdata = []\n",
    "for line in traindata:\n",
    "    newline = \"\"\n",
    "    for word in line:\n",
    "        if counts[word] <=20:\n",
    "            newline = newline + \"UNK\" + \" \"\n",
    "        else:\n",
    "            newline = newline + word + \" \"\n",
    "    newdata.append(newline)\n",
    "oldtrainines = trainlines\n",
    "trainlines = newdata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8NlCpuLbuBx"
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(trainlines)\n",
    "for line in trainlines:\n",
    "\t\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\t\tfor i in range(1, len(token_list)):\n",
    "\t\t\tsequence = token_list[:i+1]\n",
    "\t\t\tinputs.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAUJKo_mmBNK"
   },
   "outputs": [],
   "source": [
    "max_sent_len = max([len(x) for x in inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXt02Gm9UEZi"
   },
   "outputs": [],
   "source": [
    "inputs = np.array(pad_sequences(inputs, padding='pre',maxlen=max_sent_len))\n",
    "train, output = inputs[:,:-1],inputs[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwgZjCEAUF2E"
   },
   "outputs": [],
   "source": [
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WCihFBtUx_U"
   },
   "outputs": [],
   "source": [
    "output = tf.keras.utils.to_categorical(output, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thGmSkwnVBHe",
    "outputId": "322dc0d9-c2b0-43ba-8e2e-ebfa04211b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "247/247 [==============================] - 23s 78ms/step - loss: 6.1152 - accuracy: 0.0911\n",
      "Epoch 2/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 5.6820 - accuracy: 0.0959\n",
      "Epoch 3/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 5.5967 - accuracy: 0.1008\n",
      "Epoch 4/50\n",
      "247/247 [==============================] - 20s 80ms/step - loss: 5.5015 - accuracy: 0.1119\n",
      "Epoch 5/50\n",
      "247/247 [==============================] - 19s 78ms/step - loss: 5.4271 - accuracy: 0.1265\n",
      "Epoch 6/50\n",
      "247/247 [==============================] - 19s 76ms/step - loss: 5.3457 - accuracy: 0.1404\n",
      "Epoch 7/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 5.2534 - accuracy: 0.1514\n",
      "Epoch 8/50\n",
      "247/247 [==============================] - 20s 82ms/step - loss: 5.1542 - accuracy: 0.1602\n",
      "Epoch 9/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 5.0684 - accuracy: 0.1719\n",
      "Epoch 10/50\n",
      "247/247 [==============================] - 19s 78ms/step - loss: 5.0039 - accuracy: 0.1772\n",
      "Epoch 11/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.9515 - accuracy: 0.1817\n",
      "Epoch 12/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.9002 - accuracy: 0.1860\n",
      "Epoch 13/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.8604 - accuracy: 0.1888\n",
      "Epoch 14/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.8277 - accuracy: 0.1925\n",
      "Epoch 15/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.7983 - accuracy: 0.1948\n",
      "Epoch 16/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.7727 - accuracy: 0.1972\n",
      "Epoch 17/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.7468 - accuracy: 0.2002\n",
      "Epoch 18/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.7253 - accuracy: 0.2022\n",
      "Epoch 19/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.7052 - accuracy: 0.2034\n",
      "Epoch 20/50\n",
      "247/247 [==============================] - 19s 78ms/step - loss: 4.6851 - accuracy: 0.2050\n",
      "Epoch 21/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.6684 - accuracy: 0.2061\n",
      "Epoch 22/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.6528 - accuracy: 0.2079\n",
      "Epoch 23/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.6379 - accuracy: 0.2094\n",
      "Epoch 24/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.6230 - accuracy: 0.2102\n",
      "Epoch 25/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.6098 - accuracy: 0.2112\n",
      "Epoch 26/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.5969 - accuracy: 0.2127\n",
      "Epoch 27/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.5850 - accuracy: 0.2138\n",
      "Epoch 28/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.5738 - accuracy: 0.2147\n",
      "Epoch 29/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.5626 - accuracy: 0.2153\n",
      "Epoch 30/50\n",
      "247/247 [==============================] - 19s 76ms/step - loss: 4.5522 - accuracy: 0.2168\n",
      "Epoch 31/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.5437 - accuracy: 0.2172\n",
      "Epoch 32/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.5337 - accuracy: 0.2174\n",
      "Epoch 33/50\n",
      "247/247 [==============================] - 19s 78ms/step - loss: 4.5251 - accuracy: 0.2188\n",
      "Epoch 34/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.5169 - accuracy: 0.2187\n",
      "Epoch 35/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.5089 - accuracy: 0.2195\n",
      "Epoch 36/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.5021 - accuracy: 0.2200\n",
      "Epoch 37/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4948 - accuracy: 0.2208\n",
      "Epoch 38/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4847 - accuracy: 0.2209\n",
      "Epoch 39/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4793 - accuracy: 0.2211\n",
      "Epoch 40/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4732 - accuracy: 0.2217\n",
      "Epoch 41/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4643 - accuracy: 0.2225\n",
      "Epoch 42/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4595 - accuracy: 0.2229\n",
      "Epoch 43/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4535 - accuracy: 0.2237\n",
      "Epoch 44/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4483 - accuracy: 0.2236\n",
      "Epoch 45/50\n",
      "247/247 [==============================] - 19s 78ms/step - loss: 4.4422 - accuracy: 0.2239\n",
      "Epoch 46/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4357 - accuracy: 0.2245\n",
      "Epoch 47/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4316 - accuracy: 0.2248\n",
      "Epoch 48/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4247 - accuracy: 0.2254\n",
      "Epoch 49/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4210 - accuracy: 0.2259\n",
      "Epoch 50/50\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 4.4165 - accuracy: 0.2257\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embeddings (Embedding)      (None, 149, 30)           68430     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 30)                7320      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2281)              70711     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 146,461\n",
      "Trainable params: 146,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 30, input_length=max_sent_len-1,name='embeddings'))\n",
    "model.add(LSTM(30, batch_input_shape=(2000,None,None)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train, output, epochs=50, verbose=1,batch_size=2000)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CK1D_Xh7T9tv"
   },
   "outputs": [],
   "source": [
    "print(len(tokenizer.word_index) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbgkKeR7pIRY",
    "outputId": "754b7062-b303-4ebe-e747-da4e32cc7870"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_emd/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_emd/my_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fe8da34f650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model\n",
      "assets\tkeras_metadata.pb  saved_model.pb  variables\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model_emd\n",
    "model.save('saved_model_emd/my_model') \n",
    "# my_model directory\n",
    "!ls saved_model_emd\n",
    "\n",
    "# Contains an assets folder, saved_model.pb, and variables folder.\n",
    "!ls saved_model_emd/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJNJG-PvVoy_"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_model_emd/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train Perplexity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cc0O-1fshYBG"
   },
   "outputs": [],
   "source": [
    "newtestlines = []\n",
    "for line in testlines:\n",
    "    linesplit = line.split()\n",
    "    testtext = \"\"\n",
    "    for word in linesplit:\n",
    "        if counts[word] <= 20:\n",
    "            testtext = testtext + \"UNK\" + \" \"\n",
    "        else:\n",
    "            testtext = testtext + word + \" \"\n",
    "    newtestlines.append(testtext)\n",
    "\n",
    "oldtestlines = testlines\n",
    "testlines = newtestlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHwCo5XI_Lv6"
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for line in testlines:\n",
    "\t\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\t\tfor i in range(1, len(token_list)):\n",
    "\t\t\tsequence = token_list[:i+1]\n",
    "\t\t\tinputs.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dvcmmuT_tzv"
   },
   "outputs": [],
   "source": [
    "inputs = np.array(pad_sequences(inputs, maxlen=max_sent_len, padding='pre'))\n",
    "inputs = inputs[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Go0xFVtRXkem",
    "outputId": "bad934bc-6365-44e8-9704-3922cc869798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: saved_model_emd/ (stored 0%)\n",
      "  adding: saved_model_emd/my_model/ (stored 0%)\n",
      "  adding: saved_model_emd/my_model/assets/ (stored 0%)\n",
      "  adding: saved_model_emd/my_model/variables/ (stored 0%)\n",
      "  adding: saved_model_emd/my_model/variables/variables.data-00000-of-00001 (deflated 8%)\n",
      "  adding: saved_model_emd/my_model/variables/variables.index (deflated 61%)\n",
      "  adding: saved_model_emd/my_model/keras_metadata.pb (deflated 87%)\n",
      "  adding: saved_model_emd/my_model/saved_model.pb (deflated 89%)\n"
     ]
    }
   ],
   "source": [
    "! zip model1.zip -r saved_model_emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQ9f3WnBYXs"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTrpWYQUCGfV"
   },
   "outputs": [],
   "source": [
    "f = open(\"LM_test.txt\", \"w\") \n",
    "index = 0\n",
    "lineindex = 0\n",
    "perpnum = 0\n",
    "perpnumcount = 0\n",
    "for line in testlines:\n",
    "    linesplit = line.split()\n",
    "    prob = 1\n",
    "    avg_prob = 0\n",
    "    avg_prob_num = 0\n",
    "    for i in range(1,len(linesplit)):\n",
    "        predindex = tokenizer.texts_to_sequences([linesplit[i]])[0][0]\n",
    "        prob = prob * prediction[index][predindex]\n",
    "        index = index + 1\n",
    "    if prob < 1 and prob > 0:\n",
    "        avg_prob += (1/prob) ** (1/(len(linesplit) - 1))\n",
    "        avg_prob_num += 1\n",
    "    if avg_prob_num > 0:\n",
    "        print(\"{}\\t{}\".format(oldtestlines[lineindex][:-1],avg_prob/avg_prob_num),file=f)\n",
    "        perpnum += avg_prob\n",
    "        perpnumcount += 1\n",
    "    lineindex += 1\n",
    "\n",
    "print(perpnum/perpnumcount,file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l12jerA-EH7R"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_model_emd/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnsFrdmJbc0B"
   },
   "outputs": [],
   "source": [
    "f = open(\"LM_train.txt\", \"w\") \n",
    "\n",
    "inputs = []\n",
    "for line in trainlines:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        inputs.append(n_gram_sequence)\n",
    "        \n",
    "input_sequences = np.array(pad_sequences(inputs, maxlen=max_sent_len, padding='pre'))\n",
    "predictors = input_sequences[:,:-1]\n",
    "\n",
    "prediction = model.predict(predictors)\n",
    "\n",
    "index = 0\n",
    "lineindex = 0\n",
    "perpnum = 0\n",
    "perpnumcount = 0\n",
    "for line in trainlines:\n",
    "    linesplit = line.split()\n",
    "    prob = 1\n",
    "    avg_prob = 0\n",
    "    avg_prob_num = 0\n",
    "    for i in range(1,len(linesplit)):\n",
    "        predindex = tokenizer.texts_to_sequences([linesplit[i]])[0][0]\n",
    "        prob = prob * prediction[index][predindex]\n",
    "        index = index + 1\n",
    "    if prob < 1 and prob > 0:\n",
    "        avg_prob += (1/prob) ** (1/(len(linesplit) - 1))\n",
    "        avg_prob_num += 1\n",
    "    if avg_prob_num > 0:\n",
    "        print(\"{}\\t{}\".format(oldtrainines[lineindex][-1],avg_prob/avg_prob_num),file=f)\n",
    "        perpnum += avg_prob\n",
    "        perpnumcount += 1\n",
    "    lineindex += 1\n",
    "\n",
    "\n",
    "print(perpnum/perpnumcount,file=f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLPModel1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
